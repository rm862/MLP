# -*- coding: utf-8 -*-
"""G062COURSEWORK4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18E5H2gbACaV9u-m-dIsAvGwDw8ts97Kd

MACHINE LEARNING PRACTICAL: COURSEWORK 4
"""

#####################################################################
# 1) Imports & Basic Environment Checks
#####################################################################
print("GPU Info:")
gpu_info = !nvidia-smi
print("\n".join(gpu_info))

#####################################################################
# 2) Mount Google Drive
#####################################################################
from google.colab import drive
drive.mount('/content/drive')

#####################################################################
# 0) Installs libraries (not already installed in Colab)
#####################################################################
!pip install SimpleITK
!pip install torchio
!pip install segmentation-models-pytorch

# ==================== Imports ====================
import os
import random
import tarfile
import numpy as np
import cv2
import torch
import torch.optim as optim
from torch.optim.lr_scheduler import OneCycleLR
import matplotlib.pyplot as plt
import SimpleITK as sitk
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
import segmentation_models_pytorch as smp
from sklearn.model_selection import KFold
import albumentations as A
from albumentations.pytorch import ToTensorV2
import pandas as pd
import shutil
import SimpleITK as sitk
import random
import torchio as tio
from psutil import virtual_memory

#####################################################################
# 3) Configuration Toggles & Parameters
#####################################################################
TARGET_SPACING = (1.0, 1.0, 1.0)  # Adjust if heavy interpolation is undesirable
WINDOW_INTENSITIES = True        # Toggle to clamp CT intensities to [HU_LOW, HU_HIGH]
HU_LOW, HU_HIGH = -100, 400      # Example window for abdominal CT
DO_LABEL_SWAP = False            # Set True if you really need to swap label IDs
SWAP_MAP = {1: 2, 2: 1}          # e.g. 1 ↔ 2
DEBUG_PRINT = True               # Print metadata info for debugging


raw_tar_path = "/content/drive/MyDrive/Task08_HepaticVessel.tar"
extraction_dir = "Task08_HepaticVessel"

#####################################################################
# 4) Helpful Print/Debug Functions
#####################################################################
def print_image_info(image, title=""):
    """ Print metadata (spacing, origin, direction) for debugging. """
    if not DEBUG_PRINT:
        return
    spacing = image.GetSpacing()
    origin = image.GetOrigin()
    direction = image.GetDirection()
    size = image.GetSize()
    print(f"\n--- {title} ---")
    print(f"Size (xyz):    {size}")
    print(f"Spacing (xyz): {spacing}")
    print(f"Origin (xyz):  {origin}")
    print(f"Direction:     {direction}")

#####################################################################
# 5) Preprocessing Functions
#####################################################################
def standardize_orientation(image):
    """Convert to RAS orientation."""
    return sitk.DICOMOrient(image, 'RAS')

def window_intensity(image, low=HU_LOW, high=HU_HIGH):
    """Clamp intensities to [low, high]."""
    array = sitk.GetArrayFromImage(image).astype(np.float32)
    array = np.clip(array, low, high)
    out_img = sitk.GetImageFromArray(array)
    out_img.CopyInformation(image)
    return out_img

def resample_image(image, target_spacing, interp):
    """Resample to new spacing (xyz)."""
    original_spacing = image.GetSpacing()
    original_size = image.GetSize()
    new_size = [
        int(np.round(original_size[i] * (original_spacing[i] / target_spacing[i])))
        for i in range(3)
    ]
    resample = sitk.ResampleImageFilter()
    resample.SetOutputSpacing(target_spacing)
    resample.SetSize(new_size)
    resample.SetInterpolator(interp)
    resample.SetOutputDirection(image.GetDirection())
    resample.SetOutputOrigin(image.GetOrigin())
    return resample.Execute(image)

def normalize_intensity_zscore(image):
    """Per-volume Z-score normalization."""
    array = sitk.GetArrayFromImage(image).astype(np.float32)
    mean, std = np.mean(array), np.std(array)
    if std < 1e-6:
        std = 1e-6
    norm_array = (array - mean) / std
    out_img = sitk.GetImageFromArray(norm_array)
    out_img.CopyInformation(image)
    return out_img

def preprocess_image(image_path, output_path):
    """Preprocess a CT image: orientation -> optional window -> resample -> normalize."""
    image = sitk.ReadImage(image_path)
    print_image_info(image, title=f"Original Image: {os.path.basename(image_path)}")

    image = standardize_orientation(image)

    if WINDOW_INTENSITIES:
        image = window_intensity(image, HU_LOW, HU_HIGH)

    image = resample_image(image, TARGET_SPACING, interp=sitk.sitkBSpline)
    image = normalize_intensity_zscore(image)

    print_image_info(image, title="Preprocessed Image")
    sitk.WriteImage(image, output_path)
    print(f"Processed image saved: {output_path}\n")

def preprocess_label(label_path, output_path):
    """Preprocess a label: orientation -> nearest-neighbor resample -> optional ID swap."""
    label = sitk.ReadImage(label_path)
    print_image_info(label, title=f"Original Label: {os.path.basename(label_path)}")

    label = standardize_orientation(label)
    label = resample_image(label, TARGET_SPACING, interp=sitk.sitkNearestNeighbor)

    # If needed, swap IDs
    if DO_LABEL_SWAP:
        arr = sitk.GetArrayFromImage(label)
        new_arr = np.zeros_like(arr)
        for old_val, new_val in SWAP_MAP.items():
            new_arr[arr == old_val] = new_val
        label = sitk.GetImageFromArray(new_arr)
        label.CopyInformation(label)  # preserve metadata

    print_image_info(label, title="Preprocessed Label")
    sitk.WriteImage(label, output_path)
    print(f"Processed label saved: {output_path}\n")

# 6.1 - Extract Data (if needed)
if os.path.exists(raw_tar_path):
    with tarfile.open(raw_tar_path, 'r') as tar:
        tar.extractall(path=".")
    print(f"Extracted data to: {extraction_dir}")
else:
    print("No .tar file found. Skipping extraction.")

# 6.2 - Remove Hidden/Extra Files
def remove_extra_files(folder):
    if not os.path.exists(folder):
        return
    for file_ in os.listdir(folder):
        if file_.startswith(".") or file_.startswith("._"):
            path_ = os.path.join(folder, file_)
            if os.path.isdir(path_):
                shutil.rmtree(path_)
            else:
                os.remove(path_)

img_folder = os.path.join(extraction_dir, "imagesTr")
lbl_folder = os.path.join(extraction_dir, "labelsTr")
remove_extra_files(img_folder)
remove_extra_files(lbl_folder)

# 6.3 - Check Matching Filenames
def check_matching_files(image_folder, label_folder):
    img_files = sorted([f for f in os.listdir(image_folder) if f.endswith(".nii.gz")])
    lbl_files = sorted([f for f in os.listdir(label_folder) if f.endswith(".nii.gz")])
    if len(img_files) != len(lbl_files):
        print(f"WARNING: {len(img_files)} images vs {len(lbl_files)} labels.")
    else:
        print("Images & labels count is consistent.")

    for im, lb in zip(img_files, lbl_files):
        if im.split('.')[0] != lb.split('.')[0]:
            print(f"Filename mismatch: {im} vs {lb}")
    return img_files, lbl_files

image_files, label_files = check_matching_files(img_folder, lbl_folder)

# 6.4 - Preprocessing the Entire Set
preproc_img_dir = os.path.join(extraction_dir, "Preprocessed_images")
preproc_lbl_dir = os.path.join(extraction_dir, "Preprocessed_labels")
os.makedirs(preproc_img_dir, exist_ok=True)
os.makedirs(preproc_lbl_dir, exist_ok=True)

print("\nStarting preprocessing of images & labels...")
for f in image_files:
    ipath = os.path.join(img_folder, f)
    opath = os.path.join(preproc_img_dir, f)
    preprocess_image(ipath, opath)

for f in label_files:
    ipath = os.path.join(lbl_folder, f)
    opath = os.path.join(preproc_lbl_dir, f)
    preprocess_label(ipath, opath)
print("\nPreprocessing complete!")

#####################################################################
# 7) Splitting into Train/Val
#####################################################################
split_dir = os.path.join(extraction_dir, "split_dataset")
train_img_dir = os.path.join(split_dir, "train", "images")
train_lbl_dir = os.path.join(split_dir, "train", "labels")
val_img_dir   = os.path.join(split_dir, "val",   "images")
val_lbl_dir   = os.path.join(split_dir, "val",   "labels")

for d in [train_img_dir, train_lbl_dir, val_img_dir, val_lbl_dir]:
    os.makedirs(d, exist_ok=True)

preproc_images = sorted([f for f in os.listdir(preproc_img_dir) if f.endswith(".nii.gz")])
preproc_labels = sorted([f for f in os.listdir(preproc_lbl_dir) if f.endswith(".nii.gz")])

all_pairs = list(zip(preproc_images, preproc_labels))
random.seed(42)
random.shuffle(all_pairs)
split_ratio = 0.85
split_idx = int(split_ratio * len(all_pairs))
train_pairs = all_pairs[:split_idx]
val_pairs   = all_pairs[split_idx:]
print(f"Total samples: {len(all_pairs)} | Train: {len(train_pairs)} | Val: {len(val_pairs)}")

# Copy to respective folders
for (imgf, lblf) in train_pairs:
    shutil.copy(os.path.join(preproc_img_dir,  imgf), os.path.join(train_img_dir, imgf))
    shutil.copy(os.path.join(preproc_lbl_dir, lblf), os.path.join(train_lbl_dir, lblf))

for (imgf, lblf) in val_pairs:
    shutil.copy(os.path.join(preproc_img_dir,  imgf), os.path.join(val_img_dir, imgf))
    shutil.copy(os.path.join(preproc_lbl_dir, lblf), os.path.join(val_lbl_dir, lblf))

print("Train/Val split done!")

#####################################################################
# 8)Archive the Final Split to Drive
#####################################################################
archive_name = "split_dataset"
shutil.make_archive(archive_name, 'tar', root_dir=split_dir)
dest_path = os.path.join("/content/drive/MyDrive", f"{archive_name}.tar")
shutil.move(f"{archive_name}.tar", dest_path)
print(f"Archived dataset saved to: {dest_path}")

#####################################################################
# 9) Quick Visualization of a Random Sample
#####################################################################
def visualize_sample(image_path, label_path, slice_idx=None):
    image = sitk.ReadImage(image_path)
    label = sitk.ReadImage(label_path)
    img_np = sitk.GetArrayFromImage(image)
    lbl_np = sitk.GetArrayFromImage(label)

    if slice_idx is None:
        slice_idx = img_np.shape[0] // 2

    fig, ax = plt.subplots(1, 2, figsize=(12, 5))
    ax[0].imshow(img_np[slice_idx], cmap='gray')
    ax[0].set_title("Image")
    ax[1].imshow(img_np[slice_idx], cmap='gray')
    ax[1].imshow(lbl_np[slice_idx], alpha=0.5)
    ax[1].set_title("Overlay (Label)")
    plt.show()

# Example: visualize the first training sample
train_imgs = sorted(os.listdir(train_img_dir))
train_lbls = sorted(os.listdir(train_lbl_dir))
if len(train_imgs) > 0:
    sample_image_path = os.path.join(train_img_dir, train_imgs[0])
    sample_label_path = os.path.join(train_lbl_dir, train_lbls[0])
    visualize_sample(sample_image_path, sample_label_path, slice_idx=50)

print("All Done! Colab+Drive preprocessing pipeline complete.")

import os
import tarfile

# Path to the archived dataset tar file in Drive
tar_path = "/content/drive/MyDrive/split_dataset.tar"

# Choose where you want to extract it on Drive
extract_path = "/content/drive/MyDrive/extracted_split_dataset"
os.makedirs(extract_path, exist_ok=True)

# Extract
with tarfile.open(tar_path, 'r') as tar:
    tar.extractall(path=extract_path)

print(f"Extraction complete! Dataset is now in: {extract_path}")

def visualize_image_and_label(image_path, label_path, slice_idx=None):
    """
    Loads a 3D .nii.gz image and its corresponding label,
    then displays a single slice for both side-by-side.
    """
    # Read with SimpleITK
    image_itk = sitk.ReadImage(image_path)
    label_itk = sitk.ReadImage(label_path)

    # Convert to numpy arrays: shape (D, H, W)
    image_np = sitk.GetArrayFromImage(image_itk)
    label_np = sitk.GetArrayFromImage(label_itk)

    # Default to the middle slice if none is provided
    if slice_idx is None:
        slice_idx = image_np.shape[0] // 2

    print(f"Visualizing slice {slice_idx} of {os.path.basename(image_path)}")
    print(f"Image shape: {image_np.shape} | Label shape: {label_np.shape}")

    # Plot side-by-side
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Left: the raw image
    axes[0].imshow(image_np[slice_idx], cmap='gray')
    axes[0].set_title("Image Slice")

    # Right: overlay label on the same slice
    axes[1].imshow(image_np[slice_idx], cmap='gray')
    axes[1].imshow(label_np[slice_idx], cmap='jet', alpha=0.4)
    axes[1].set_title("Image + Label Overlay")

    plt.show()


extracted_base = "/content/drive/MyDrive/extracted_split_dataset"

train_img_dir = os.path.join(extracted_base, "train", "images")
train_lbl_dir = os.path.join(extracted_base, "train", "labels")

# List all .nii.gz files
train_imgs = sorted([f for f in os.listdir(train_img_dir) if f.endswith(".nii.gz")])
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith(".nii.gz")])

if len(train_imgs) != len(train_lbls):
    print(f"Warning: #images={len(train_imgs)} vs #labels={len(train_lbls)}.")
else:
    print(f"Found {len(train_imgs)} image/label pairs.")

# Pick a random pair
random_idx = random.randint(0, len(train_imgs) - 1)
img_file = train_imgs[random_idx]
lbl_file = train_lbls[random_idx]

img_path = os.path.join(train_img_dir, img_file)
lbl_path = os.path.join(train_lbl_dir, lbl_file)

# Visualize
visualize_image_and_label(img_path, lbl_path, slice_idx=50)  # or any slice index you want

###############################################################################
#  A) Pad-or-Crop Function
###############################################################################
def pad_or_crop_to_shape(sitk_image, target_shape=(256,256,256)):
    array = sitk.GetArrayFromImage(sitk_image)  # (D,H,W)
    dd, hh, ww = array.shape
    TD, TH, TW = target_shape

    out_array = np.zeros((TD, TH, TW), dtype=array.dtype)

    def center_slice_for_target(orig_size, new_size):
        start = max((new_size - orig_size)//2, 0)
        end = start + min(orig_size, new_size)
        return slice(start, end)

    def center_slice_for_orig(orig_size, new_size):
        start = max((orig_size - new_size)//2, 0)
        end = start + min(orig_size, new_size)
        return slice(start, end)

    # Destination slices
    dstD = center_slice_for_target(dd, TD)
    dstH = center_slice_for_target(hh, TH)
    dstW = center_slice_for_target(ww, TW)

    # Source slices
    srcD = center_slice_for_orig(dd, TD)
    srcH = center_slice_for_orig(hh, TH)
    srcW = center_slice_for_orig(ww, TW)

    out_array[dstD, dstH, dstW] = array[srcD, srcH, srcW]

    out_sitk = sitk.GetImageFromArray(out_array)
    out_sitk.SetSpacing(sitk_image.GetSpacing())
    out_sitk.SetDirection(sitk_image.GetDirection())
    out_sitk.SetOrigin(sitk_image.GetOrigin())
    return out_sitk

###############################################################################
#  B) Function to Remove Leading/Trailing Spaces in Filenames
###############################################################################
def clean_filenames(folder):
    """
    For every file in `folder`,
    1) If the filename has leading/trailing spaces, rename it to a stripped version.
    2) Optionally could fix other hidden chars, but this is a minimal approach.
    """
    for fname in os.listdir(folder):
        original_path = os.path.join(folder, fname)
        # Skip subfolders or non-file items if any
        if not os.path.isfile(original_path):
            continue
        clean_name = fname.strip()  # remove leading/trailing whitespace
        # If the stripped name differs, renames
        if clean_name != fname:
            new_path = os.path.join(folder, clean_name)
            print(f"Renaming:\n  '{fname}' -> '{clean_name}'")
            os.rename(original_path, new_path)

# Path to your split dataset
split_dataset_dir = "/content/drive/MyDrive/extracted_split_dataset"

train_img_dir = os.path.join(split_dataset_dir, "train", "images")
train_lbl_dir = os.path.join(split_dataset_dir, "train", "labels")
val_img_dir   = os.path.join(split_dataset_dir, "val", "images")
val_lbl_dir   = os.path.join(split_dataset_dir, "val", "labels")

# Path to store the resized version
resized_root = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset"
resized_train_img_dir = os.path.join(resized_root, "train", "images")
resized_train_lbl_dir = os.path.join(resized_root, "train", "labels")
resized_val_img_dir   = os.path.join(resized_root, "val",   "images")
resized_val_lbl_dir   = os.path.join(resized_root, "val",   "labels")

for d in [resized_train_img_dir, resized_train_lbl_dir, resized_val_img_dir, resized_val_lbl_dir]:
    os.makedirs(d, exist_ok=True)

# Desired final shape
TARGET_SHAPE = (256, 256, 256)

# 1) Cleanup any trailing/leading spaces in filenames
print("Cleaning filenames in train images/labels, val images/labels...")
clean_filenames(train_img_dir)
clean_filenames(train_lbl_dir)
clean_filenames(val_img_dir)
clean_filenames(val_lbl_dir)

# 2) Now gather the sorted filenames
train_imgs = sorted([f for f in os.listdir(train_img_dir) if f.endswith(".nii.gz")])
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith(".nii.gz")])
val_imgs   = sorted([f for f in os.listdir(val_img_dir)   if f.endswith(".nii.gz")])
val_lbls   = sorted([f for f in os.listdir(val_lbl_dir)   if f.endswith(".nii.gz")])

# Check if counts match (optional)
if len(train_imgs) != len(train_lbls):
    print(f"WARNING: #train images={len(train_imgs)} != #train labels={len(train_lbls)}")
if len(val_imgs) != len(val_lbls):
    print(f"WARNING: #val images={len(val_imgs)} != #val labels={len(val_lbls)}")

##############################################################
#  Resize train set
##############################################################
for img_name, lbl_name in zip(train_imgs, train_lbls):
    img_path = os.path.join(train_img_dir, img_name)
    lbl_path = os.path.join(train_lbl_dir, lbl_name)
    # Double-check the file physically exists
    if not os.path.isfile(img_path):
        print(f"Skipping: {img_path} doesn't exist.")
        continue
    if not os.path.isfile(lbl_path):
        print(f"Skipping: {lbl_path} doesn't exist.")
        continue

    # Attempt to read
    try:
        sitk_img = sitk.ReadImage(img_path)
        sitk_lbl = sitk.ReadImage(lbl_path)
    except Exception as e:
        print(f"Failed reading {img_path} or {lbl_path}. Error:\n{e}")
        continue

    # Pad or crop
    resized_img = pad_or_crop_to_shape(sitk_img, TARGET_SHAPE)
    resized_lbl = pad_or_crop_to_shape(sitk_lbl, TARGET_SHAPE)

    # Save
    out_img_path = os.path.join(resized_train_img_dir, img_name)
    out_lbl_path = os.path.join(resized_train_lbl_dir, lbl_name)
    sitk.WriteImage(resized_img, out_img_path)
    sitk.WriteImage(resized_lbl, out_lbl_path)

    print(f"Resized train pair: {img_name} & {lbl_name}")

##############################################################
#  Resize val set
##############################################################
for img_name, lbl_name in zip(val_imgs, val_lbls):
    img_path = os.path.join(val_img_dir, img_name)
    lbl_path = os.path.join(val_lbl_dir, lbl_name)
    # Double-check the file physically exists
    if not os.path.isfile(img_path):
        print(f"Skipping: {img_path} doesn't exist.")
        continue
    if not os.path.isfile(lbl_path):
        print(f"Skipping: {lbl_path} doesn't exist.")
        continue

    try:
        sitk_img = sitk.ReadImage(img_path)
        sitk_lbl = sitk.ReadImage(lbl_path)
    except Exception as e:
        print(f"Failed reading {img_path} or {lbl_path}. Error:\n{e}")
        continue

    resized_img = pad_or_crop_to_shape(sitk_img, TARGET_SHAPE)
    resized_lbl = pad_or_crop_to_shape(sitk_lbl, TARGET_SHAPE)

    out_img_path = os.path.join(resized_val_img_dir, img_name)
    out_lbl_path = os.path.join(resized_val_lbl_dir, lbl_name)
    sitk.WriteImage(resized_img, out_img_path)
    sitk.WriteImage(resized_lbl, out_lbl_path)

    print(f"Resized val pair: {img_name} & {lbl_name}")

print("Resizing complete! All train/val sets have shape:", TARGET_SHAPE)

def visualize_image_and_label(image_path, label_path, slice_idx=None):
    """
    Loads a 3D .nii.gz image and label,
    then displays a single slice from each side-by-side.
    If slice_idx is None, we default to the middle slice.
    """
    # Read images with SimpleITK
    image_itk = sitk.ReadImage(image_path)
    label_itk = sitk.ReadImage(label_path)

    # Convert to NumPy arrays of shape (D, H, W)
    img_np = sitk.GetArrayFromImage(image_itk)
    lbl_np = sitk.GetArrayFromImage(label_itk)

    # Choose a slice (middle if not specified)
    if slice_idx is None:
        slice_idx = img_np.shape[0] // 2

    print(f"Showing slice {slice_idx} of {os.path.basename(image_path)}")
    print(f"  Image shape: {img_np.shape} | Label shape: {lbl_np.shape}")

    # Plot side by side
    fig, axes = plt.subplots(1, 2, figsize=(12, 6))

    # Left: raw image
    axes[0].imshow(img_np[slice_idx], cmap='gray')
    axes[0].set_title("Image Slice")

    # Right: overlay label
    axes[1].imshow(img_np[slice_idx], cmap='gray')
    axes[1].imshow(lbl_np[slice_idx], cmap='jet', alpha=0.4)
    axes[1].set_title("Overlay Label")

    plt.show()

# ===========================
# Paths to your resized data
# ===========================
resized_root = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset"

train_img_dir = os.path.join(resized_root, "train", "images")
train_lbl_dir = os.path.join(resized_root, "train", "labels")
val_img_dir   = os.path.join(resized_root, "val",   "images")
val_lbl_dir   = os.path.join(resized_root, "val",   "labels")

# List the filenames in train images and labels
train_imgs = sorted([f for f in os.listdir(train_img_dir) if f.endswith(".nii.gz")])
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith(".nii.gz")])

print(f"Train images: {len(train_imgs)} files")
print(f"Train labels: {len(train_lbls)} files")

# ===========================
# Example: Visualize a random pair from train set
# ===========================
if len(train_imgs) > 0:
    # pick a random index
    idx = random.randint(0, len(train_imgs)-1)
    img_name = train_imgs[idx]
    lbl_name = train_lbls[idx]

    img_path = os.path.join(train_img_dir, img_name)
    lbl_path = os.path.join(train_lbl_dir, lbl_name)

    # Show slice #100 or the middle slice
    visualize_image_and_label(img_path, lbl_path, slice_idx=100)
else:
    print("No training images found in the resized dataset folder!")

# ===========================
# Example: Visualize a few validation pairs in a loop
# ===========================
val_imgs = sorted([f for f in os.listdir(val_img_dir) if f.endswith(".nii.gz")])
val_lbls = sorted([f for f in os.listdir(val_lbl_dir) if f.endswith(".nii.gz")])

print(f"Validation images: {len(val_imgs)} files")
print(f"Validation labels: {len(val_lbls)} files")

# Let’s visualize the first 3 validation pairs (or fewer if not enough exist)
num_to_show = min(3, len(val_imgs), len(val_lbls))
for i in range(num_to_show):
    img_name = val_imgs[i]
    lbl_name = val_lbls[i]
    img_path = os.path.join(val_img_dir, img_name)
    lbl_path = os.path.join(val_lbl_dir, lbl_name)

    # Show slice #80 or the middle
    visualize_image_and_label(img_path, lbl_path, slice_idx=80)

def inspect_label(label_path):
    """
    Reads a label file, prints its shape, unique values,
    and (optionally) bounding box of nonzero region.
    """
    # Read
    lbl_itk = sitk.ReadImage(label_path)
    lbl_arr = sitk.GetArrayFromImage(lbl_itk)  # shape (D,H,W)

    # Basic info
    print(f"Label: {os.path.basename(label_path)}")
    print(f"  Size (Z, Y, X): {lbl_itk.GetSize()} (i.e. array shape={lbl_arr.shape})")

    # Unique values
    uniques = np.unique(lbl_arr)
    print(f"  Unique values: {uniques}")

    # If all zero or only one value, we can skip bounding box
    if len(uniques) == 1 and uniques[0] == 0:
        print("  --> Label is entirely background (all zeros).")
        return

    # Otherwise, find the bounding box of nonzero region
    nonzero_indices = np.argwhere(lbl_arr != 0)
    zmin, ymin, xmin = nonzero_indices.min(axis=0)
    zmax, ymax, xmax = nonzero_indices.max(axis=0)
    print(f"  Nonzero bounding box: Z:{zmin}..{zmax}, Y:{ymin}..{ymax}, X:{xmin}..{xmax}")
    print("-"*50)

# Set the path to your Resized dataset
resized_root = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset"

# Subfolders
train_img_dir = os.path.join(resized_root, "train", "images")
train_lbl_dir = os.path.join(resized_root, "train", "labels")
val_img_dir   = os.path.join(resized_root, "val",   "images")
val_lbl_dir   = os.path.join(resized_root, "val",   "labels")

# Gather sorted filenames
train_imgs = sorted([f for f in os.listdir(train_img_dir) if f.endswith(".nii.gz")])
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith(".nii.gz")])
val_imgs   = sorted([f for f in os.listdir(val_img_dir) if f.endswith(".nii.gz")])
val_lbls   = sorted([f for f in os.listdir(val_lbl_dir) if f.endswith(".nii.gz")])

# Check train set
print("\n=== Checking train set ===")
for img_name, lbl_name in zip(train_imgs, train_lbls):
    lbl_path = os.path.join(train_lbl_dir, lbl_name)
    # Inspect
    inspect_label(lbl_path)

# Check val set
print("\n=== Checking val set ===")
for img_name, lbl_name in zip(val_imgs, val_lbls):
    lbl_path = os.path.join(val_lbl_dir, lbl_name)
    inspect_label(lbl_path)

label_path = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset/train/labels/hepaticvessel_004.nii.gz"
label_itk = sitk.ReadImage(label_path)

# 2) Convert to NumPy
lbl_arr = sitk.GetArrayFromImage(label_itk)

# 3) Computes how many voxels are label=1 vs label=2
mask1 = (lbl_arr == 1)
mask2 = (lbl_arr == 2)
print("Mask1 has", mask1.sum(), "voxels.")
print("Mask2 has", mask2.sum(), "voxels.")

import matplotlib.pyplot as plt

slice_idx = 100  # or another slice in the bounding-box range
image_slice = lbl_arr[slice_idx]  # the label array or the raw image array

# For the raw image, read the associated .nii.gz and do the same slicing
# Then overlay mask1 or mask2 in different colors

# For example, if raw image is in `img_arr`:
#   plt.imshow(img_arr[slice_idx], cmap='gray')

# Then overlay mask1 in red
mask1_slice = (lbl_arr[slice_idx] == 1)
plt.imshow(mask1_slice, cmap='Reds', alpha=0.4)

# Then overlay mask2 in blue
mask2_slice = (lbl_arr[slice_idx] == 2)
plt.imshow(mask2_slice, cmap='Blues', alpha=0.4)

plt.show()

def count_label_voxels(label_path):
    """
    Loads a 3D label volume from 'label_path' and counts how many voxels ==1 and ==2.
    Returns (count_1, count_2).
    """
    lbl_itk = sitk.ReadImage(label_path)
    lbl_arr = sitk.GetArrayFromImage(lbl_itk)

    mask1 = (lbl_arr == 1)
    mask2 = (lbl_arr == 2)
    return mask1.sum(), mask2.sum()

resized_root = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset"

# Train
train_lbl_dir = os.path.join(resized_root, "train", "labels")
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith(".nii.gz")])

print("=== Train Set ===")
for lbl_name in train_lbls:
    lbl_path = os.path.join(train_lbl_dir, lbl_name)
    c1, c2 = count_label_voxels(lbl_path)
    print(f"{lbl_name} => label=1 has {c1} voxels, label=2 has {c2} voxels.")

# Validation
val_lbl_dir = os.path.join(resized_root, "val", "labels")
val_lbls = sorted([f for f in os.listdir(val_lbl_dir) if f.endswith(".nii.gz")])

print("\n=== Validation Set ===")
for lbl_name in val_lbls:
    lbl_path = os.path.join(val_lbl_dir, lbl_name)
    c1, c2 = count_label_voxels(lbl_path)
    print(f"{lbl_name} => label=1 has {c1} voxels, label=2 has {c2} voxels.")

def find_bounding_box(label_array):
    """
    Returns (zmin, zmax) for the bounding box of nonzero voxels in a 3D array.
    If label is all zero, returns None, None.
    """
    nonzero = np.argwhere(label_array != 0)
    if len(nonzero) == 0:
        return None, None
    zmin = nonzero[:,0].min()
    zmax = nonzero[:,0].max()
    return zmin, zmax

def visualize_random_slice(img_path, lbl_path):
    """
    Reads the 3D image and label, picks a random slice within the label's
    bounding box in the Z dimension, and displays them side-by-side.
    """
    # Read them
    img_itk = sitk.ReadImage(img_path)
    lbl_itk = sitk.ReadImage(lbl_path)

    # Convert to NumPy arrays
    img_arr = sitk.GetArrayFromImage(img_itk)  # (D, H, W)
    lbl_arr = sitk.GetArrayFromImage(lbl_itk)  # (D, H, W)

    # Find bounding box in Z dimension
    zmin, zmax = find_bounding_box(lbl_arr)
    depth = img_arr.shape[0]

    # If label is entirely zero, just pick middle or a random slice
    if zmin is None or zmax is None:
        slice_idx = depth // 2
        print(f"{os.path.basename(lbl_path)} => Entirely zero label, showing middle slice {slice_idx}")
    else:
        # pick a random slice in [zmin, zmax]
        slice_idx = random.randint(zmin, zmax)
        print(f"{os.path.basename(lbl_path)} => Random slice in bounding box: {slice_idx} (Z range: {zmin}..{zmax})")

    # Plots side by side
    fig, axes = plt.subplots(1, 2, figsize=(12,6))

    # Left: raw image
    axes[0].imshow(img_arr[slice_idx], cmap='gray')
    axes[0].set_title(f"Image Slice {slice_idx}")

    # Right: overlay label
    axes[1].imshow(img_arr[slice_idx], cmap='gray')
    axes[1].imshow(lbl_arr[slice_idx], cmap='jet', alpha=0.4)
    axes[1].set_title("Overlay Label")

    plt.show()

# ============================================
resized_root = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset"

train_img_dir = os.path.join(resized_root, "train", "images")
train_lbl_dir = os.path.join(resized_root, "train", "labels")

val_img_dir   = os.path.join(resized_root, "val", "images")
val_lbl_dir   = os.path.join(resized_root, "val", "labels")

# Lists all training image/label pairs
train_imgs = sorted([f for f in os.listdir(train_img_dir) if f.endswith('.nii.gz')])
train_lbls = sorted([f for f in os.listdir(train_lbl_dir) if f.endswith('.nii.gz')])

# 1) Visualises a few random volumes from the train set
num_to_show = 5
random_indices = random.sample(range(len(train_imgs)), min(num_to_show, len(train_imgs)))

for idx in random_indices:
    img_name = train_imgs[idx]
    lbl_name = train_lbls[idx]
    img_path = os.path.join(train_img_dir, img_name)
    lbl_path = os.path.join(train_lbl_dir, lbl_name)
    visualize_random_slice(img_path, lbl_path)

val_imgs = sorted([f for f in os.listdir(val_img_dir) if f.endswith('.nii.gz')])
val_lbls = sorted([f for f in os.listdir(val_lbl_dir) if f.endswith('.nii.gz')])

# We'll also pick e.g. 3 volumes from val
val_indices = random.sample(range(len(val_imgs)), min(3, len(val_imgs)))

for idx in val_indices:
    img_name = val_imgs[idx]
    lbl_name = val_lbls[idx]
    img_path = os.path.join(val_img_dir, img_name)
    lbl_path = os.path.join(val_lbl_dir, lbl_name)
    visualize_random_slice(img_path, lbl_path)

!nvidia-smi

# Sets seeds for reproducibility
seed = 42
random.seed(seed)
np.random.seed(seed)
torch.manual_seed(seed)
torch.cuda.manual_seed_all(seed)

# ==================== Utils ====================
def normalize_ct(slice_np, min_val=-1000, max_val=1000):
    slice_clipped = np.clip(slice_np, min_val, max_val)
    slice_norm = (slice_clipped - min_val) / (max_val - min_val + 1e-8)
    return slice_norm

def apply_clahe(slice_np):
    slice_rescaled = (slice_np * 255).astype(np.uint8)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    enhanced = clahe.apply(slice_rescaled).astype(np.float32) / 255.0
    return enhanced

class Nifti2_5DDataset(Dataset):
    def __init__(self, images_paths, labels_paths, transforms=None):
        self.images_paths = images_paths
        self.labels_paths = labels_paths
        self.transforms = transforms

    def __len__(self):
        return len(self.images_paths)

    def __getitem__(self, idx):
        image = sitk.ReadImage(self.images_paths[idx])
        label = sitk.ReadImage(self.labels_paths[idx])
        image_np = sitk.GetArrayFromImage(image)
        label_np = sitk.GetArrayFromImage(label)
        label_np = np.where(label_np > 0, 1, 0).astype(np.float32)

        slice_idx = image_np.shape[0] // 2
        slices = image_np[slice_idx-1:slice_idx+2]

        img_stack = []
        for s in slices:
            # Conditional normalization
            if s.max() > 250 or s.min() < -200:
                s = normalize_ct(s)

            # Apply CLAHE
            s = apply_clahe(s)
            img_stack.append(s)

        img_stack = np.stack(img_stack)
        lbl_slice = label_np[slice_idx]

        if self.transforms:
            augmented = self.transforms(image=img_stack.transpose(1, 2, 0), mask=lbl_slice)
            img_stack = augmented['image'].float()
            lbl_slice = augmented['mask'].float()

        return img_stack, lbl_slice.unsqueeze(0)

train_transforms = A.Compose([
    A.HorizontalFlip(p=0.5),
    A.Rotate(limit=15, p=0.5),
    A.ElasticTransform(alpha=1, sigma=50, p=0.3),
    A.RandomGamma(p=0.3),
    A.GridDistortion(p=0.2),
    A.RandomResizedCrop((128, 128), scale=(0.8, 1.0), p=0.4),
    A.Resize(128, 128),
    ToTensorV2()
])
val_transforms = A.Compose([
    A.Resize(128, 128),
    ToTensorV2()
])

def combined_loss(outputs, targets):
    tversky = smp.losses.TverskyLoss(mode='binary', alpha=0.7, beta=0.3)
    bce = smp.losses.SoftBCEWithLogitsLoss(pos_weight=torch.tensor(20.0).to(outputs.device))
    return tversky(outputs, targets) + bce(outputs, targets)

def train_epoch(model, loader, optimizer, device):
    model.train()
    total_loss = 0
    for images, masks in tqdm(loader, desc='Training'):
        images, masks = images.to(device), masks.to(device)
        optimizer.zero_grad()
        outputs = model(images)
        loss = combined_loss(outputs, masks)
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    return total_loss / len(loader)

def validate_epoch(model, loader, device, threshold=0.5):
    model.eval()
    dice_scores = []
    losses = []
    with torch.no_grad():
        for images, masks in tqdm(loader, desc='Validation'):
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)
            loss = combined_loss(outputs, masks)
            losses.append(loss.item())
            outputs = torch.sigmoid(outputs)
            preds = (outputs > threshold).float()

            for pred, mask in zip(preds, masks):
                if mask.sum() == 0:
                    continue  # skip slices with no vessel
                intersection = (pred * mask).sum()
                union = pred.sum() + mask.sum()
                dice = (2 * intersection) / (union + 1e-8)
                dice_value = dice.item()
                if dice_value > 0.01:
                    dice_scores.append(dice_value)

    mean_loss = np.mean(losses)
    if dice_scores:
        dice_metric = np.percentile(dice_scores, 90) * 100
    else:
        dice_metric = -1
    return dice_metric, mean_loss

def visualize_prediction(model, dataset, device, epoch, fold, phase='val', save_dir="/content/drive/MyDrive/SegmentationVis"):
    model.eval()
    save_path = os.path.join(save_dir, phase)
    os.makedirs(save_path, exist_ok=True)

    predicted_pixels_list = []
    predicted_masks_raw = []

    thresholds = [0.3, 0.5, 0.7]  # ← thresholds to visualise

    for i in range(min(3, len(dataset))):
        img, mask = dataset[i]
        img_input = img.unsqueeze(0).to(device)
        mask_np = mask.squeeze().numpy()

        with torch.no_grad():
            pred = torch.sigmoid(model(img_input)).squeeze().cpu().numpy()
        predicted_masks_raw.append(pred)

        fig, axs = plt.subplots(1, len(thresholds) + 3, figsize=(5 * (len(thresholds) + 3), 4))

        # Pre-processed image
        axs[0].imshow(img[0], cmap='gray')
        axs[0].set_title("Pre-Processed Slice")
        axs[0].axis('off')

        # Ground truth
        axs[1].imshow(img[0], cmap='gray')
        axs[1].imshow(mask_np, alpha=0.5, cmap='Greens')
        axs[1].set_title("Ground Truth")
        axs[1].axis('off')

        # Show predictions at different thresholds
        for j, st in enumerate(thresholds):
            binary_mask = (pred > t)
            predicted_pixels = binary_mask.sum().item()
            predicted_pixels_list.append(predicted_pixels)

            axs[2 + j].imshow(img[0], cmap='gray')
            axs[2 + j].imshow(binary_mask, alpha=0.5, cmap='Reds')
            axs[2 + j].set_title(f"Predicted (>{t})\nPixels: {predicted_pixels}")
            axs[2 + j].axis('off')

        # Soft heatmap
        axs[-1].imshow(pred, cmap='hot')
        axs[-1].set_title("Soft Prediction Heatmap")
        axs[-1].axis('off')

        plt.tight_layout()
        plt.savefig(os.path.join(save_path, f"fold{fold}_epoch{epoch}_sample{i}.png"))
        plt.close()

    # --- Average predicted pixels over all samples and thresholds ---
    avg_predicted = sum(predicted_pixels_list) / len(predicted_pixels_list)
    print(f"[Fold {fold} | Epoch {epoch}] Average predicted vessel pixels (from visualised samples): {avg_predicted:.2f}")

    # --- Save to CSV ---
    stats_csv_path = os.path.join(save_dir, "visualisation_stats.csv")
    write_header = not os.path.exists(stats_csv_path)

    with open(stats_csv_path, "a") as f:
        if write_header:
            f.write("fold,epoch,avg_predicted_pixels\n")
        f.write(f"{fold},{epoch},{avg_predicted:.2f}\n")

    # --- Visualises average soft prediction mask ---
    avg_pred_mask = np.mean(predicted_masks_raw, axis=0)
    fig, ax = plt.subplots(figsize=(6, 5))
    ax.imshow(avg_pred_mask, cmap='hot')
    ax.set_title(f"Average Soft Prediction (Epoch {epoch})")
    ax.axis('off')
    plt.tight_layout()
    plt.savefig(os.path.join(save_path, f"fold{fold}_epoch{epoch}_avg_prediction.png"))
    plt.close()

def main_train():
    from torch.optim.lr_scheduler import ReduceLROnPlateau
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    train_img_dir = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset/train/images"
    train_lbl_dir = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset/train/labels"

    images = sorted([os.path.join(train_img_dir, f) for f in os.listdir(train_img_dir) if f.endswith('.nii.gz')])
    labels = sorted([os.path.join(train_lbl_dir, f) for f in os.listdir(train_lbl_dir) if f.endswith('.nii.gz')])

    kf = KFold(n_splits=3, shuffle=True, random_state=42)
    scores = []

    for fold, (train_idx, val_idx) in enumerate(kf.split(images)):
        print(f"Fold {fold+1}")
        train_ds = Nifti2_5DDataset([images[i] for i in train_idx], [labels[i] for i in train_idx], train_transforms)
        val_ds = Nifti2_5DDataset([images[i] for i in val_idx], [labels[i] for i in val_idx], val_transforms)

        train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=4)
        val_loader = DataLoader(val_ds, batch_size=8, shuffle=False, num_workers=4)

        model = smp.Unet(encoder_name='efficientnet-b3', encoder_weights='imagenet', in_channels=3, classes=1).to(device)
        optimizer = optim.AdamW(model.parameters(), lr=5e-4)
        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)

        best_dice = 0
        metrics = []
        for epoch in range(30):
            train_loss = train_epoch(model, train_loader, optimizer, device)
            val_dice, val_loss = validate_epoch(model, val_loader, device)
            scheduler.step(val_loss)
            print(f"Epoch {epoch+1}/30 - Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Dice: {val_dice:.2f}%")
            metrics.append({"epoch": epoch+1, "train_loss": train_loss, "val_loss": val_loss, "val_dice": val_dice})
            visualize_prediction(model, train_ds, device, epoch + 1, fold + 1, phase='train')
            visualize_prediction(model, val_ds, device, epoch + 1, fold + 1, phase='val')

            if val_dice > best_dice:
                best_dice = val_dice
                torch.save(model.state_dict(), f"best_model_foldLast{fold}.pth")

        scores.append(best_dice)
        df = pd.DataFrame(metrics)
        df.to_csv(f"/content/drive/MyDrive/fold_{fold+1}_metrics.csv", index=False)

    print(f"\nAverage Dice across folds: {np.mean(scores):.2f}%")

if __name__ == '__main__':
    main_train()
    debug_overfit_one_sample()

def debug_overfit_one_sample():
    import torch.nn as nn
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # Pick one good sample
    sample_img_path = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset/train/images/hepaticvessel_084.nii.gz"
    sample_lbl_path = "/content/drive/MyDrive/Task08_HepaticVessel/Resized_dataset/train/labels/hepaticvessel_084.nii.gz"

    dataset = Nifti2_5DDataset([sample_img_path], [sample_lbl_path], transforms=train_transforms)
    loader = DataLoader(dataset, batch_size=1, shuffle=True)

    model = smp.Unet(
        encoder_name='efficientnet-b3',
        encoder_weights='imagenet',
        in_channels=3,
        classes=1
    ).to(device)

    optimizer = optim.AdamW(model.parameters(), lr=1e-3)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)

    best_dice = 0
    for epoch in range(1, 51):
        model.train()
        total_loss = 0
        for images, masks in loader:
            images, masks = images.to(device), masks.to(device)
            optimizer.zero_grad()
            outputs = model(images)
            loss = combined_loss(outputs, masks)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        scheduler.step()

        model.eval()
        with torch.no_grad():
            images, masks = next(iter(loader))
            images, masks = images.to(device), masks.to(device)
            outputs = torch.sigmoid(model(images))
            preds = (outputs > 0.5).float()

            intersection = (preds * masks).sum()
            union = preds.sum() + masks.sum()
            dice = (2 * intersection / (union + 1e-8)).item() * 100

        print(f"[Overfit Epoch {epoch}] Loss: {total_loss:.4f} | Dice: {dice:.2f}%")

        if dice > best_dice:
            best_dice = dice
            torch.save(model.state_dict(), f"best_overfit_model.pth")

        # Visualise every 5 epochs
        if epoch % 5 == 0 or epoch == 1 or epoch == 50:
            visualize_prediction(model, dataset, device, epoch, fold=0, phase="debug")

debug_overfit_one_sample()

import pandas as pd
import matplotlib.pyplot as plt

plt.style.use("seaborn-v0_8-whitegrid")
plt.rcParams.update({
    "axes.titlesize": 16,
    "axes.labelsize": 14,
    "legend.fontsize": 12,
    "xtick.labelsize": 12,
    "ytick.labelsize": 12,
    "figure.dpi": 100,
    "axes.spines.top": False,
    "axes.spines.right": False,
    "lines.linewidth": 2
})

# Loads CSVs from Drive
folds = {
    "Fold 1": pd.read_csv("/content/drive/MyDrive/fold_1_metrics.csv"),
    "Fold 2": pd.read_csv("/content/drive/MyDrive/fold_2_metrics.csv"),
    "Fold 3": pd.read_csv("/content/drive/MyDrive/fold_3_metrics.csv")
}

colors = plt.get_cmap("tab10")

# --- Plot 1: Training & Validation Loss ---
plt.figure(figsize=(10, 6))
for i, (name, df) in enumerate(folds.items()):
    plt.plot(df["epoch"], df["train_loss"], label=f"{name} - Train", linestyle="--", color=colors(i))
    plt.plot(df["epoch"], df["val_loss"], label=f"{name} - Val", linestyle="-", color=colors(i))
plt.title("Training and Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.legend(frameon=False)
plt.tight_layout()
plt.savefig("/content/drive/MyDrive/loss_plot.png", dpi=300)  # Save to Drive
plt.show()

# --- Plot 2: Validation Dice Score ---
plt.figure(figsize=(10, 6))
for i, (name, df) in enumerate(folds.items()):
    plt.plot(df["epoch"], df["val_dice"], label=name, color=colors(i))
plt.title("Validation Dice Score")
plt.xlabel("Epoch")
plt.ylabel("Dice Score (%)")
plt.legend(frameon=False)
plt.tight_layout()
plt.savefig("/content/drive/MyDrive/dice_plot.png", dpi=300)  # Save to Drive
plt.show()





































